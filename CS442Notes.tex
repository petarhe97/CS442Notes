\documentclass[11pt]{article}
\usepackage{amsthm}
\usepackage{fullpage}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage[official]{eurosym}
\usepackage[]{algorithm2e}
\usepackage[normalem]{ulem}
\usepackage{color}
\usepackage{tcolorbox}


\newcommand{\remove}[1]{{}}
\newcommand{\ignore}[1]{{}}
\newcommand{\rednote}[1]{{\color{red} #1}}
\newcommand{\bluenote}[1]{{\color{blue} #1}}




\begin{document}

\noindent
{Winter 2020 \hfill Zi Hao He}


\begin{center}
{\large\bf CS442 Notes}
\end{center}
\bigskip

\section{Functional Programming}

\begin{itemize}
\item[-] to begin: Functional Programming in general, not a particular language
\item[-] need a model \begin{itemize}
\item[-] simple
\item[-] powerful enough to be useful
\end{itemize}
\end{itemize}

\textbf{Church-Turing Thesis:} Any algorithm can be simulated on a Turing machine. \\

\textbf{Alan Turing}
\begin{itemize}
\item[-] Turing machine
\item[-] not an inspiring model for programming
\end{itemize}

\textbf{Alonzo Church}
\begin{itemize}
\item[-] $\lambda$-calculus
\item[-] equivalent to Turing Machines
\item[-] the basis for all of functional programming
\end{itemize}

\subsection{Untyped Lambda-Calculus}

\textbf{Calculus}
\begin{itemize}
\item[-] a system or method of calculation
\item[-] syntax + rules for manipulating syntax
\end{itemize}
\textbf{Lambda-Calculus} (1934) - "a calculus of functions" \\ \\
\textbf{Syntax}: Abstract Syntax
\begin{align*}
& variable, abstraction, application \\
<expr> &::= <var> | <abs> | <app> \\
<var> &::= a | b | c \\
& \text{variable and body} \\
<abs> &::= \lambda <var>.<expr> \\
& \text{rator and rand} \\
<app> &::= <expr> <expr>
\end{align*}

Use parenthesis to disambiguate parses \\

\textbf{Conventions:}
\begin{enumerate}
\item Abstractions extend as far to the right as possible
	\begin{itemize}
		\item[e.g.] $\lambda x.y\;z = \lambda x.(y\;z) \neq (\lambda x.y)\;z$
	\end{itemize}
\item Applications associate left-to-right
	\begin{itemize}
		\item[e.g.] $x\;y\;z = (x\;y)\;z \neq x\;(y\;z)$
	\end{itemize}
\end{enumerate}

\textbf{Interpretation}
	\begin{itemize}
		\item[-] Var: Self explanatory
		\item[-] Abs: $\lambda x.E =$ "function" taking argument x and returning expr E
		\item[-] App: $M\;N$ - result of applying "function" M to argument N
	\end{itemize}

\textbf{Consider:}
\begin{itemize}
\item[] $\lambda x.x$ - Here the first $x$ is a binding occurrence and second $x$ is a bound occurrence.
\item[] $\lambda x.x\;y\;x$ - The $y$ is a free occurrence (fully parenthesized function is $\lambda x.((x\;y)\;x)$)
\item[] $\lambda x.x\;(\lambda x.x)\;x$ - Same variable name might be bound in difference places as long as the scope is not clashing
\item[] $x\;\lambda x.x$ - The $x$ in the front is free while the other one is bound
\end{itemize}

\textbf{Informally:}
\begin{itemize}
\item[] A variable is bound if it has a bound occurrence.
\item[] A variable is free if it has a free occurrence
\item[] The same variable can be used in both bound and free occurrences
\end{itemize}

\textbf{Formally:} \\

\textbf{Definition:} Let E be an expression. The bound variables of E, $B \cup [E]$ are given by 
\begin{itemize}
	\item[] $B \cup [x] = \emptyset$
	\item[] $B \cup [\lambda x.E] = B \cup [E] \cup \{x\}$
	\item[] $B \cup [M\;N] = B \cup [M] \cup B \cup [N]$
\end{itemize}


$x$ is bound in $E$ if $x \in B \cup [E]$ \\

The free variables of $E$, $F \cup [E]$ are given by
\begin{itemize}
	\item[] $F \cup [x] = \{x\}$
	\item[] $F \cup [\lambda x.E] = F \cup [E] \setminus \{x\}$
	\item[] $F \cup [M\;N] = F \cup [M] \cup F \cup [N]$
\end{itemize}

$x$ is free in $E$ if $x \in F \cup [E]$ \\

A variable can be both bound and free: $F \cup [x\; \lambda x.x] = B \cup [x\; \lambda x.x] = \{x\}$ \\

But each occurrence is either bound or free, not both \\

Two occurrences of a variable $x$ "mean the same thing" if
\begin{enumerate}
\item they are both free occurrences
\item OR they have the same binding occurrence
\end{enumerate}

$\lambda x.\lambda y.y\;x$ and $\lambda a.\lambda b.b\;a$ these should mean the same thing \\

$\lambda x.y\;x$ and $\lambda x.w\;x$ should not mean the same thing because $y$ and $w$ do not have to be the same free variable \\

You can change the names of bound variables, but not free ones. \\

\textbf{Formally:} \\

\textbf{Definition ($\alpha$-conversion):} For all $x$, $y$, $M$, $\lambda x.M =_\alpha \lambda y.M[y/x]$ if $y \notin F \cup [M]$ \\

$M[N/x] =$ "substitute $N$ for $x$ in $M$" \\

More generally, if $C[\lambda x.M]$ denotes an expr in which $\lambda x.M$ occurs as a subexpression, then $C[\lambda x.M] =_\alpha C[\lambda y.M[y/x]]$ if $y \notin F \cup [M]$. \\

e.g. 
\begin{itemize}
	\item[] $\lambda x.x =_\alpha \lambda y.y$
	\item[] $x\;\lambda x.x =_\alpha x\;\lambda a.a$
	\item[] $\lambda a.b\;a =_\alpha \lambda c.b\;c \neq_\alpha \lambda b.b\;b \neq_\alpha \lambda a.d\;a$
\end{itemize}

\textbf{Computation:} \\

Expr. $(\lambda x.M)\;N$ is called a ($\beta$-)redex (reductible expression) \\

We expect: $(\lambda x.M)\;N \Rightarrow$ evaluate $M$, with $N$ substituted for $x$ i.e. $M[N/x]$ \\

\textbf{Definition ($\beta$-reduction):} For all $M$, $N$, $x$, $(\lambda x.M)\;N \rightarrow_\beta M[N/x]$ \\

More generally - for all contexts $C$, $C[(\lambda x.M)\;N] \rightarrow_\beta C[M[N/x]]$ \\

$\rightarrow_\beta$ is a binary relation on terms

\begin{itemize}
	\item[] $A \rightarrow_\beta B$: $A$ beta reduces to $B$ in one step
	\item[] $A \rightarrow_\beta^n B$: $A$ beta reduces to $B$ in $n$ steps
	\item[] $A \rightarrow_\beta^* B$: $A$ beta reduces to $B$ in 0 or more steps
	\item[] $A \rightarrow_\beta^+ B$: $A$ beta reduces to $B$ in 1 or more steps
\end{itemize}

\textbf{Evaluating $M[N/x]$} \\

Want: Substitute $N$ for all free occurrences of $x$ in $M$ \\

\textbf{Definition (substitution, naive(wrong)):} 
\begin{itemize}
	\item[] $x[E/x] = E$
	\item[] $y[E/x] = y$, $y \neq x$
	\item[] $(M\;N)[E/x] = M[E/x]\;N[E/x]$
	\item[] $(\lambda x.P)[E/x] = \lambda x.P$
	\item[] $(\lambda y.P)[E/x] = \lambda y. P[E/x]$, $y \neq x$
\end{itemize}

E.g. 
\begin{align*}
(\lambda x.x\;y)\;z &\rightarrow_\beta (x\;y)[z/x] \\
&= x[z/x]\;y[z/x] \\
&= z\;y \\ \\
(\lambda x.x)\;a &\rightarrow_\beta x[a/x] = a \\ \\
(\lambda x. \lambda y.x)\;a\;b &\rightarrow_\beta (\lambda y.x)[a/x]\;b \\
&= (\lambda y.x[a/x])\;b \\
&= (\lambda y.a)\;b \\
&\rightarrow_\beta a[b/y] \\
&= a \\ \\
(\lambda x. \lambda y.y)\;a\;b &\rightarrow_\beta (\lambda y.y)[a/x]\;b \\
&= (\lambda y.y[a/x])\;b \\
&= (\lambda y.y)\;b \\
&\rightarrow_\beta y[b/y] \\
&= b
\end{align*}

\textbf{Consider:}
\begin{align*}
(\lambda x. \lambda y.x)\;y\;w &\rightarrow_\beta (\lambda y.x)[y/x]\;w \\
&= (\lambda y.x[y/x])\;w \\
&= (\lambda y.y)\;w \\
&\rightarrow_\beta y[w/y] \\
&= w
\end{align*}

We can see from this that the last rule of $(\lambda y.P)[E/x] = \lambda y.P[E/x]$, $y \neq x$ must be wrong. \\

What happened? Free variable $y$ became bound after substitution \\

As a result, the binding occurrence of $x$ changed \\

$\lambda x.\lambda y.x \leftarrow$ the inner $x$ is bound to the $\lambda x$ on the outside. \\

This is called {\bf Dynamic binding} - meaning of variables uncertain until runtime \\

We want {\bf static binding} - meanings of variables fixed before runtime \\

\textbf{Definition (substitution, fixed):}
\begin{itemize}
	\item[] $x[E/x] = E$
	\item[] $y[E/x] = y$, $y \neq x$
	\item[] $(M\;N)[E/x] = M[E/x]\;N[E/x]$
	\item[] $(\lambda x.P)[E/x] = \lambda x.P$
	\item[] $(\lambda y.P)[E/x] = \lambda y. P[E/x]$, $y \notin F \cup [E]$
	\item[] $(\lambda y.P)[E/x] = \lambda z.(P[z/y][E/x])$, $y \in F \cup [E]$, $z$ a "fresh" variable
\end{itemize}

Now 
\begin{align*}
(\lambda x.\lambda y.x)\;y\;w &\rightarrow_\beta (\lambda y.x)[y/x]\;w \\
&= (\lambda z.x[z/y][y/x])\;w \\
&= (\lambda z.x[y/x])\;w \\
&= (\lambda z.y)\;w \\
&\rightarrow_\beta y[w/z] \\
&= y
\end{align*}

{\bf Computation:} $\beta$-reduction until you reach a {\bf Normal Form}. \\

\textbf{Definition ($\beta$-Normal Form):} An expr is in $\beta$ Normal Form if it has no $\beta$-redices. \\

\textbf{Definition (Weak Normal Form):} An expr is in Weak Normal Form if the only $\beta$-redices are inside abstractions. e.g. $\lambda z.(\lambda x.x)\;y$. \\

Usually, "Normal Form" will mean $\beta$-Normal Form. \\

{\bf Consider:} 
\begin{align*}
(\lambda x.x)((\lambda y.y)\;z) &\rightarrow_\beta x[((\lambda y.y)\;z)/x] \\
&= (\lambda y.y)\;z \\
&\rightarrow_\beta y[z/y] \\
&= z
\end{align*}

Or

\begin{align*}
(\lambda x.x)((\lambda y.y)\;z) &\rightarrow_\beta (\lambda x.x)(y[z/y]) \\
&= (\lambda x.x)\;z \\
&\rightarrow_\beta x[z/x] \\
&= z
\end{align*}

- two difference reduction sequences. Does it matter which we take? \\

\textbf{Theorem (Church-Rosser):} Let $E_1,E_2,E_3$ be expressions such that $E_1 \rightarrow_\beta^* E_2$ and $E_1 \rightarrow_\beta^* E_3$. Then there is an expression $E_4$ such that (up to $\alpha$-equivalence) $E_2 \rightarrow_\beta^* E_4$ and $E_3 \rightarrow_\beta^* E_4$. \\

{\bf Immediate Consequence -} An expr $E$ can have at most one $\beta$-Normal Form (modulo $\alpha$-equivalence) \\

Do all expressions have a $\beta$-NF? No!\\

{\bf Consider:}
\begin{align*}
(\lambda x.x\;x)(\lambda x.x\;x) &\rightarrow_\beta (x\;x)[(\lambda x.x\;x)/x] \\
&= (\lambda x.x\;x)(\lambda x.x\;x)
\end{align*}

It does not have a $\beta$-NF because it always reduces to itself. \\

Which exprs have a $\beta$-NF? - undecidable - equivalent to Halting Problem \\

{\bf Consider:}
\begin{align*}
(\lambda x.y)((\lambda x.x\;x)(\lambda x.x\;x)) \rightarrow_\beta (\lambda x.y)((\lambda x.x\;x)(\lambda x.x\;x)) \rightarrow_\beta \cdots
\end{align*}

Or, the alternate way of reducing this

\begin{align*}
(\lambda x.y)((\lambda x.x\;x)(\lambda x.x\;x)) &\rightarrow_\beta y[(\lambda x.x\;x)(\lambda x.x\;x)/x] \\
&= y
\end{align*}

$\therefore$ Order does matter when $\infty$-reductions are possible. \\

{\bf Reduction Strategies} - "plans" for choosing a redex to reduce. \\

{\bf Applicative Order Reductions (AOR)}: Choose the leftmost, innermost redex. 
\begin{itemize}
	\item[-] Innermost = not containing any other redex 
	\item[-] This is called "eager evaluation" 
\end{itemize}

{\bf Normal Order Reduction (NOR):} Choose the leftmost,outermost
\begin{itemize}
	\item[-] outermost = not contained in any other redex
	\item[-] "lazy evaluation"
\end{itemize}

To the example earlier, the one the results in infinite reduction is AOR and the one that go the $\beta$-NF form is NOR. \\

e.g. 
\begin{align*}
(\lambda x.x)((\lambda y.y)\;z) &\xrightarrow{\text{AOR}}_\beta (\lambda x.x)\;z \xrightarrow{\text{AOR}}_\beta z \\
(\lambda x.x)((\lambda y.y)\;z) &\xrightarrow{\text{NOR}}_\beta (\lambda y.y)\;z \xrightarrow{\text{NOR}}_\beta z
\end{align*}

{\bf Theorem (Standardization):} If an expr as a $\beta$-NF, then NOR is guaranteed to reach it. \\

But most proramming languages use applicative order, including Scheme. \\

{\bf $\eta$-reduction:} Consider $(\lambda x.y\;x)\;z \rightarrow_\beta (y\;x)[z/x] = y\;z$ \\

So $\lambda x.y\;x$ behaves exactly like $z$ \\

\textbf{Definition ($\eta$-reduction):} $\lambda x.M\;x \rightarrow_\eta M$ if $x \notin F \cup [M]$ \\

More generally, $C[\lambda x.M\;x] \rightarrow_\eta C[M]$ if $x \notin F \cup [M]$ \\

So we have $\lambda x.y\;x \rightarrow_\eta y$ \\

\subsection{Programming in the $\lambda$-Calculus}

Shorthand for convenience: $[[\cdot]]$: (real-world programming language) $\rightarrow \lambda$-calculus \\

For a real-world expr $E$, $[[E]]$ is our representation of $E$ in the $\lambda$-calculus \\

e.g. $[[id]] = \lambda x.x$ \\

{\bf Note:} $[[\cdot]]$ is just shorthand. An expression containing $[[\cdot]]$ is not $\lambda$-calculus until all $[[\cdot]]$s have been replaced with what they represent. \\

{\bf Booleans:} Let $[[$true$]] = \lambda x.\lambda y.x$ and $[[$false$]] = \lambda x.\lambda y.y$. \\

if <bool> then <true-part> else <false-part> \\

if($b,t,f$) = if $b$ then $t$ else $f$ \\ 

$[[$if$]] = \lambda b. \lambda t.\lambda f.b\;t\;f$ \\

Note that $\lambda b. \lambda t.\lambda f.b\;t\;f \rightarrow_\eta^2 \lambda b.b$ \\

Alternatively, $[[$if B then T else F$]] = [[B]][[T]][[F]]$ \\

Does it work? \\

\begin{align*}
[[\text{if true then P else Q}]] &= [[true]][[P]][[Q]] \\
&= (\lambda x.\lambda y.x)[[P]][[Q]] \\
&\rightarrow_\beta [[P]]
\end{align*}

\begin{align*}
[[\text{if false then P else Q}]] &= [[false]][[P]][[Q]] \\
&= (\lambda x.\lambda y.y)[[P]][[Q]] \\
&\rightarrow_\beta [[Q]]
\end{align*}

Now, for the definition of {\bf Not}:

\begin{align*}
[[not]] &= \lambda b.[[\text{if b then false else true}]] \\
&= \lambda b.b[[false]][[true]] \\
&= \lambda b.b(\lambda x.\lambda y.y)(\lambda x.\lambda y.x)
\end{align*}

We can test it:

\begin{align*}
[[\text{not true}]] &= (\lambda b.b[[false]][[true]])\;[[true]] \\
&\rightarrow_\beta [[true]][[false]][[true]] \\
&= (\lambda x.\lambda y.x)[[false]][[true]] \\
&\rightarrow_\beta^2 [[false]]
\end{align*}

For the definition of {\bf And}: 

\begin{align*}
[[and]] &= \lambda p.\lambda q.[[\text{if p then q else false}]] \\
&= \lambda p.\lambda q.p\;q\;[[false]]
\end{align*}

For the definition of {\bf Or}: 

\begin{align*}
[[and]] &= \lambda p.\lambda q.[[\text{if p then true else q}]] \\
&= \lambda p.\lambda q.p\;[[true]]\;q
\end{align*}

\textbf{Storage:} Use lists. Scheme - lists based on pairs.
\begin{itemize}
	\item[] (cons a b) creates the pair
	\item[] (cons a (cons b c)) creates the list
	\item[] $\therefore$ nested pairs create lists
\end{itemize}

{\bf Need to implement:}
\begin{itemize}
	\item cons
	\item nil - empty list
	\item null? - is the list empty?
	\item car - first component of the pair
	\item cdr - 2nd component of the pair
\end{itemize}

{\bf Modelling pairs:} pair - function that takes a {\bf selector} as a parameter \\

If the selector is true - return the first component \\

If the selector is true - return the second component \\

i.e. $[[pair]] = \lambda s.[[$if s then h else t$]]$ where s is the selector, h is the head, t is the tail. \\

So $[[pair]] = \lambda s.s\;h\;t$ \\

Then $[[cons]] = \lambda h.\lambda t.\lambda s.s\;h\;t$ \\

e.g. 
\begin{align*}
[[\text{cons a (cons b nil)}]] &= [[cons]]\;a\;([[cons]]\;b\;[[nil]]) \\
&= (\lambda h.\lambda t.\lambda s.s\;h\;t)\;a\;([[cons]]\;b\;[[nil]]) \\
&\rightarrow_\beta^2 \lambda s.s\;a\;([[cons]]\;b\;[[nil]]) \\
&= \lambda s.s\;a((\lambda h.\lambda t.\lambda s.s\;h\;t)\;b\;[[nil]]) \\
&\rightarrow_\beta^2 \lambda s.s\;a\;(\lambda s.s\;b\;[[nil]]) 
\end{align*}

{\bf car:} return the head $\Rightarrow$ pass the selector "true" \\

$[[car]] = \lambda l.l\;[[true]] = \lambda l.l\;(\lambda x.\lambda y.x)$ \\

Similarly, {\bf cdr:} return the tail $\Rightarrow$ pass the selector "false" \\

$[[cdr]] = \lambda l.l\;[[false]] = \lambda l.l\;(\lambda x.\lambda y.y)$ \\

{\bf null?}
\begin{itemize}
	\item[-] must return false when given a pair $(\lambda s.s\;h\;t)$
	\item[-] pass a selector that consumes h and t, returns false
\end{itemize}

i.e. $[[null?]] = \lambda l.l(\lambda a.\lambda b.[[false]]) = \lambda l.l(\lambda a.\lambda b.\lambda x.\lambda y.y)$ \\

\begin{align*}
[[null?]](\lambda s.s\;h\;t) &= (\lambda l.l(\lambda a.\lambda b.\lambda x.\lambda y.y))(\lambda s.s\;h\;t) \\
&\rightarrow_\beta (\lambda s.s\;h\;t)(\lambda a.\lambda b.\lambda x.\lambda y.y) \\
&\rightarrow_\beta (\lambda a.\lambda b.\lambda x.\lambda y.y)\;h\;t \\
&\rightarrow_\beta^2  \lambda x.\lambda y.y \\
&= [[false]]
\end{align*}

{\bf nil:} something to make null? return true. \\

$[[nil]] = \lambda s.[[true]] = \lambda s.\lambda x.\lambda y.x$

\begin{align*}
[[null?]][[nil]] &= (\lambda l.l(\lambda a.\lambda b.\lambda x.\lambda y.y))(\lambda s.\lambda x.\lambda y.x) \\
&\rightarrow_\beta (\lambda s.\lambda x.\lambda y.x)(\lambda a.\lambda b.\lambda x.\lambda y.y) \\
&\rightarrow_\beta \lambda x.\lambda y.x \\
&= [[true]]
\end{align*}

\textbf{Numbers}
\begin{itemize}
	\item[-] Consider only non-negative integers
	\item[-] Easy - encode n as a list of length n
		\begin{itemize}
			\item[] $[[0]] = [[nil]]$
			\item[] $[[1]] = \lambda s.s\;?\;[[nil]]$ where $?$ is just whatever
			\item[] $[[2]] = \lambda s.s\;?\;(\lambda s.s\;?\;[[nil]])$
		\end{itemize}
\end{itemize}

{\bf Primitives:} $[[pred]], [[succ]], [[isZero?]]$ \\

$[[isZero?]] = [[null?]]$ \\

$[[pred]] = [[cdr]]$ \\

$[[succ]] = \lambda n.\lambda s.s\;?\;n ( = \lambda n.[[cons]]\;?\;n)$ \\

{\bf Exercise:} $[[pred\;(succ\;m)]] =_\beta m$ \\

\textbf{Clever Solution: Church Numberals} \\

Represent n as the act of applying a function f n times to an argument x. \\

$[[0]] = \lambda f.\lambda x.x$ \\

$[[1]] = \lambda f.\lambda x.f\;x$\\

$[[2]] = \lambda f.\lambda x.f\;(f\;x)$\\

$[[3]] = \lambda f.\lambda x.f\;(f\;(f\;x))$\\

$[[n]]\;f\;x = f^n(x)$ \\

{\bf addition:} $m + n$ - apply f n times to x, then apply f m times to the result \\

$[[+]] = \lambda m.\lambda n.\lambda f.\lambda x.m\;f\;(n\;f\;x)$ \\

\begin{align*}
[[+\;2\;3]] &= (\lambda m.\lambda n.\lambda f.\lambda x.m\;f\;(n\;f\;x))(\lambda f.\lambda x.f\;(f\;x))(\lambda f.\lambda x.f(f(f\;x))) \\
&\rightarrow_\beta^2 \lambda f.\lambda x(\lambda f.\lambda x.f(f\;x))\;f\;((\lambda f.\lambda x.f(f\;x)))\;f\;x) \\
&\rightarrow_\beta \lambda f.\lambda x.(\lambda x.f(f\;x))(\lambda f.\lambda x.f(f(f\;x)))\;f\;x) \\
&\rightarrow_\beta \lambda f.\lambda x.f(f((\lambda f.\lambda x.f(f(f\;x)))\;f\;x)) \\
&\rightarrow_\beta \lambda f.\lambda x.f(f((\lambda x.f(f(f(\;x)))\;x) \\
&\rightarrow_\beta \lambda f.\lambda x.f(f(f(f(f\;x)))) \\
&= [[5]]
\end{align*}

{\bf Special case:} $[[succ]] = \lambda n.\lambda f.\lambda x.n\;f\;(f\;x)$ (or $f(n\;f\;x))$ \\

\textbf{Subtraction:} Harder - find a function to apply n times to produce $[[n-1]]$ \\

{\bf Consider:} Start with $[[cons\;0\;0]]$ \\

apply the function $f:[[cons\;a\;b]] \rightarrow [[cons\;a+1\;a]]$ \\

n times: $[[cons\;n\;n-1]]$ - then take the cdr. \\

$[[pred]] = \lambda n.[[cdr]]\;(n\;(\lambda p.[[cons]]([[succ]][[car\;p]])\;[[car\;p]])([[cons]][[0]][[0]]))$ \\

$[[-]] = \lambda m.\lambda n.n\;[[pred]]\;m$ \\

{\bf Multiplication:} Apply the n-fold repetition of f, m times \\

$[[*]] = \lambda m.\lambda n.\lambda f.\lambda x.m\;(n\;f)\;x =_\eta \lambda m. \lambda n.\lambda f.m\;(n\;f)$ \\

Since $n\;f = f^n$, then $m\;(n\;f) = (f^n)^m$ \\

Notice that if you change $m$ and $n$ to $f$ and $g$, and $f$ to $x$, you get $f(g(x))$ which is just function composition. \\

{\bf Exponentiation:} $m^n$ - the n-fold repetition of m itself \\

$[[\;\widehat{}\;]] = \lambda m.\lambda n.\lambda f.\lambda x.n\;m\;f\;x =_\eta \lambda m.\lambda n.n\;m$ \\

\textbf{Recursion:} find the length of a list 
\begin{align*}
[[len]] &= \lambda l.[[\text{if (null? $l$) 0 (succ (len (cdr l)))]]}\\
&= \lambda l.\text{([[null?]] $l$) [[0]] ([[succ]] ([[len]] ([[cdr]] $l$)))}
\end{align*}

{\bf WRONG!} [[len]] defined in terms of itself. \\

How do we get a closed-form representation of len? Solve the equation. \\

{\bf Aside:} fixed points. A {\bf fixed point} of a function f is a value x such that $x = f(x)$ \\

e.g. $f(x) = x^2 - 6$ has a fixed point of 3 since $f(3) = 3$ 
\begin{align*}
[[len]]&=\lambda l.([[null?]]\;l)[[0]]([[succ]]([[len]]([[cdr]]\;l)))\\
&\leftarrow_\beta (\lambda f.\lambda l.([[null?]]\;l)[[0]]([[succ]](f\;([[cdr]]\;l))))\;[[len]] \\
&=_\beta F([[len]])\text{     where F = $(\lambda f.\lambda l.([[null?]]\;l)[[0]]([[succ]](f\;([[cdr]]\;l))))$}
\end{align*}

[[len]] satisfies $[[len]] = F([[len]])$ \\

$\therefore$ Need a fixed point of $F$ \\

{\bf Consider:}
\begin{align*}
X &= (\lambda x.f(x\;x))(\lambda x.f(x\;x)) \\
&\rightarrow_\beta f((\lambda x.f(x\;x))(\lambda x.f(x\;x))) \\
&= f(X) \\
\end{align*}

$\therefore$ X is a fixed point of f \\

Now parameterize by f, get

$$Y = \lambda f.(\lambda x.f(x\;x))(\lambda x.f(x\;x))$$

This is {\bf Curry's Paradoxical Combinator} (or Y combinator) \\

- returns the fixed point of any function \\

\begin{align*}
Y\;g &= (\lambda f.(\lambda x.f(x\;x))(\lambda x.f(x\;x)))\;g \\
&\rightarrow_\beta (\lambda x.g(x\;x))(\lambda x.g(x\;x)) \\
&\rightarrow_\beta g((\lambda x.g(x\;x))(\lambda x.g(x\;x))) \\
&\rightarrow_\beta g(Y\;g) 
\end{align*}

$\therefore$ for any {\bf $g$, $Y\;g =_\beta g(Y\;g)$}. i.e. Y g is a fixed point of g. \\

Any combinator (closed expression) C such that for all g, $C\;g =_\beta g(C\;g)$ is called a {\bf fixed-point combinator}. \\

$\therefore$ $[[len]] = Y\;F = Y(\lambda f.\lambda l.([[null?]]\; l)\;[[0]]\;([[succ]]\;(f\;([[cdr]]\;l)))$ \\

e.g.
\begin{align*}
& [[len]]\;([[cons]]\;a\;([[cons]]\;b\;[[nil]]) \\ 
&=_\beta [[len]]\;(\lambda s.s\;a\;(\lambda s.s\;b\;[[nil]])) \\\
&= Y;F(\lambda s.s\;a\;(\lambda s.s\;b\;[[nil]])) \\
&= (\lambda f.(\lambda x.f(x\;x))(\lambda x.f(x\;x))\;F\;(\lambda s.s\;a\;(\lambda s.s\;b\;[[nil]])) \text{   done through NOR reduction}\\
&\rightarrow_\beta (\lambda x.F(x\;x))(\lambda x.F(x\;x))(\lambda s.s\;a\;(\lambda s.s\;b\;[[nil]])) \\
&\rightarrow_\beta F((\lambda x.F(x\;x))(\lambda x.F(x\;x)))(\lambda s.s\;a\;(\lambda s.s\;b\;[[nil]])) \\
&= (\lambda f.\lambda l.([[null?]]\; l)\;[[0]]\;([[succ]]\;(f\;([[cdr]]\;l)))((\lambda x.F(x\;x))(\lambda x.F(x\;x)))(\lambda s.s\;a\;(\lambda s.s\;b\;[[nil]])) \\
&\rightarrow_\beta (\lambda l.([[null?]]\;l)\;[[0]]\;([[succ]]\;(((\lambda x.F(x\;x))(\lambda x.F(x\;x)))\; ([[cdr]]\;l))))(\lambda s.s\;a\;(\lambda s.s\;b\;[[nil]])) \\
&\rightarrow_\beta ([[null?]]\;(\lambda s.s\;a\;(\lambda s.s\;b\;[[nil]])))\;[[0]]\;([[succ]]\;(((\lambda x.F(x\;x))(\lambda x.F(x\;x)))\; ([[cdr]]\;(\lambda s.s\;a\;(\lambda s.s\;b\;[[nil]]))))) \\
&\rightarrow_\beta^* [[false]]\;[[0]]\;[[succ]](((\lambda x.F(x\;x))(\lambda x.F(x\;x)))\;([[cdr]]\;(\lambda s.s\;a\;(\lambda s.s\;b\;[[nil]])))) \\
&\rightarrow_\beta^2 [[succ]]\;(((\lambda x.F(x\;x))(\lambda x.F(x\;x)))\;([[cdr]]\;(\lambda s.s\;a\;(\lambda s.s\;b\;[[nil]])))) \\
&\rightarrow_\beta^* [[succ]](((\lambda x.F(x\;x))(\lambda x.F(x\;x)))\;(\lambda s.s\;b\;[[nil]]))\text{     Not NOR-done for brevity}\\
&\text{We can see a pattern here} \\
&\rightarrow_\beta^* [[succ]]([[succ]]\;((\lambda x.F(x\;x))(\lambda x.F(x\;x)))([[cdr]]\;(\lambda s.s\;b\;[[nil]])))) \\
&\rightarrow_\beta^* [[succ]]([[succ]]((\lambda x.F(x\;x))(\lambda x.F(x\;x)))[[nil]]) \\
&\rightarrow_\beta [[succ]]([[succ]] (F\;((\lambda x.F(x\;x))(\lambda x.F(x\;x))))[[nil]]])\\
&= [[succ]]([[succ]]((\lambda f.\lambda l.([[null?]]\; l)\;[[0]]\;([[succ]]\;(f\;([[cdr]]\;l)))\;((\lambda x.F(x\;x))(\lambda x.F(x\;x))) [[nill]]) \\
&\rightarrow_\beta^2 [[succ]]([[succ]]\;([[null?]][[nil]])\;[[0]]\;([[succ]]\;((\lambda x.F(x\;x))(\lambda x.F(x\;x))))\;([[cdr]][[nil]])) \\
&\rightarrow_\beta^* [[succ]]([[succ]]\;[[true]]\;[[0]]\;([[succ]]\;((\lambda x.F(x\;x))(\lambda x.F(x\;x))))\;([[cdr]][[nil]]))  \\
&\rightarrow_\beta^2 [[succ]]([[succ]]\;0) \\
&\rightarrow_\beta^2 [[2]]
\end{align*}

- Works under NOR, but not under AOR. \\

For recursion under eager evaluation, need 3 things:
\begin{itemize}
	\item[1)] Modified reduction strategy - Applicative Order Evaluation (AOE)
	\begin{itemize}
		\item[-] choose the leftmost, innermost redex that is not within the body of an abstraction
	\end{itemize}
	\item[2)] Modified Y combinator
	\begin{itemize}
		\item[-] $Y' = \lambda f.(\lambda x.f(\lambda y.x\;x\;y))(\lambda x.f(\lambda y.x\;x\;y))$
		\item[] Note: $Y' \rightarrow_\eta^2 Y$
	\end{itemize}
	\item[3)] "Short-circuit if-then-else"
	\begin{itemize}
		\item[] [[if B then T else F]] [[B]] $(\lambda x.[[T]])$ $(\lambda x.[[F]])$ x
	\end{itemize}
\end{itemize}

\pagebreak
\subsection{Scheme \& Functional Programming}

See notes, Chapter 3 \\

- "pure" functional programming - No side effects, no mutation, no mutation, no state, no I/O \\

$\Rightarrow$ referential transparency - output of a function is completely determined by its input \\

Consequence - "equals can be substituted for equals" \\

e.g. (let ((z (f 3))) $\cdots$) - anywhere z occurs, can substitute (f 3), and vice versa\\

- Not possible in the presence of side-effects. \\

\textbf{Higher-Order Functions} \\

Functions are {\bf first-class values} - can be
\begin{itemize}
	\item[1)]  passed as parameters
	\item[2)] returned by functions
	\item[3)] stored as data
\end{itemize}

Functions that take or return other functions are called {\bf higher-order functions}  \\

e.g. map, foldl, foldr\\

{\bf Consider:} $\lambda x.\lambda y.x$  $(lambda x.\lambda y.x)\;a\;b \rightarrow_\beta^2 a$ \\

- takes 2 arguments and returns the first \\

In Scheme: (lambda (x) (lambda (y) x)) \\

(((lambda (x) (lambda (y) x)) 1) 2) \\

This form (lambda (x) (lambda (y) x)) called {\bf curried}. \\

- simulate multi-argument functions with functions that return functions \\

Advantage - partial application \\

(define plus (lambda (x) (lambda (y) (+ x y)))) \\

(define f (plus 5)) - save for later use - f is a function that adds 5\\

(f 1) $\Rightarrow$ 6 \\

(f 8) $\Rightarrow$ 13 \\

{\bf Implemented}

- first-class functions implemented as a {\bf closure} \\

- a pair [function code | env] \\

- pointer to function code, pointer to the environment in which the function was defined. \\

This is how f knows what x was when (plus 5) was called. \\

\pagebreak

\section{Type Theory} 

Consider [[true id]] 
\begin{align*}
[[true]][[id]] &= (\lambda x.\lambda y.x)(\lambda z.z) \\
&\rightarrow_\beta \lambda y.\lambda z.z \\
&= [[false]]
\end{align*}

(true id) produces false. Makes sense? NO! \\

Unrestricted combinations $\Rightarrow$ unexpected results. - only do things that make sense \\

How? Introduce a system of {\bf types}
\begin{itemize}
	\item[-] set of values an expression can have
	\item[-] interpretation of raw data
\end{itemize}

{\bf Type System} - set of types and set of rules for assigning types \\

An expression is {\bf well-typed} if a type is derivable for it from the type rules - else it is {\bf ill-typed} \\

Strong vs weak typing - how strictly are type rules enforced? \\

Static vs Dynamic Typing
\begin{itemize}
	\item[-] When are types determined
		\begin{itemize}
			\item[-] static-at-compile-time (C)
			\item[-] dynamic-at-run-time (Scheme)
		\end{itemize}
\end{itemize}

Monomorphic vs. Polymorphic typing
\begin{itemize}
	\item[monomorphic-] entities have a unique type
	\item[polymorphic-] entities can have multiple types
\end{itemize}

We study strong,static, monomorphic (for now) typing. \\

\subsection{The Simply-Typed $\lambda$-Calculus (monomorphic}

{\bf Syntax:}
\begin{align*}
<expr> &::= <var>\;|\;<abs>\;|\;<app> \\
<var> &::= a\;|\;b\;|\;c\;|\cdots \\
<abs> &::= \lambda <var>\;:\;<type>.<expr> \\
<app> &::= <expr><expr> \\
<type> &::= <primitive>\;|\;<constructed> \\
<primitive> &::= t_1|t_2|\cdots \\
<constructed> &::= <type> \rightarrow <type> \\
\end{align*}

{\bf Primitive types} - "built-in", e.g. int, bool, $t_1$, $t_2$, ... \\

{\bf Constructed types} 
\begin{itemize}
	\item[-] built from other types
	\item[-] component types and type constructor
\end{itemize}

e.g. int $\rightarrow$ bool - "function taking int and returning bool" \\

- the $\rightarrow$ is type constructor for functions \\

$\rightarrow$: right-to-left associative \\

$t_1 \rightarrow t_2 \rightarrow t_3 = t_1 \rightarrow (t_2 \rightarrow t_3) \neq (t_1 \rightarrow t_2) \rightarrow t_3$ \\

\subsection{Type Checking/Inference}

Type theory $\cong$ Intuitionist Implicational Logic (subset of propositional logic) \\

- called the Curry-Howard Isomorphism \\

Rules expressed as a formal inference system. \\

$\frac{premises}{conclusion}$ \\

$\frac{P_1 \cdots P_n}{C} = $ "If we can construct proofs of $P_1 \cdots P_n$, we have a proof of C. \\

No premises: $\frac{}{conclusion}$ - axioms - conclusion always holds \\

Eg.(logic): "modus ponens" $\frac{p\rightarrow q\;p}{q}$ \\

$\frac{a\;b}{a \land b}$ ($\land$ introduction) \\

$\frac{a \land b}{a}$  $\frac{a \land b}{b}$ ($\land$ elimination) \\

\subsection{Type rules for Simply Typed $\lambda$-Calculus} 

type environment
\begin{itemize}
	\item[-] map from identifiers to types
	\item[-] list of <name,type> pairs - "symbol table"
	\item[-] denoted A ("assumptions") or $\Gamma$ 
\end{itemize}

A(x) = "look up x in A" - if $<x,\tau > \in$ A, A(x) = $\tau$ \\

{\bf Type judgement} - statement of the form $A \vdash E:\tau$ \\

- $\vdash$ turnstile $\equiv$ derivability \\

Variables - look up in environment \\

The course notes says $\frac{A(x) = \tau}{A \vdash x:\tau}\;[var]$ \\

We are going with $\frac{}{A \vdash x:A(x)}\;[var]$ to save some writing \\

{\bf Abstractions} - assume the param has the given type, then type the body\\

$$\frac{A + <x_1,\tau_1> \vdash E:\tau_2}{A \vdash (\lambda x:\tau_1\;.\;E):\tau_1 \rightarrow \tau_2}\;[abs]$$

{\bf Applications}
\begin{itemize}
	\item[-] type the rator and rand
	\item[-] type of the rand must match the param type of the rator
	\item[-] type of expr is the result type of the rator
\end{itemize}

$$\frac{A \vdash M:\tau_1 \rightarrow \tau_2 \;\; A \vdash N:\tau_1}{A \vdash M\;N:\tau_2}\;[app]$$

$$\frac{\tau_1 \rightarrow \tau_2 \;\; \tau_1}{\tau_2}$$

Ex. find the type of $\lambda x:t_1.x$ \\

$$\frac{\frac{}{\{<x,t_1>\} \vdash x:t_1}\;[var]}{\{\} \vdash (\lambda x:t_1.x):t_1 \rightarrow t_1}\;[abs]$$

Eg. $\lambda x:t_1. \lambda y:t_1 \rightarrow t_2.\;y\;x$ \\

$$\frac{\frac{\frac{\frac{}{\{<x,t_1>,<y, t_1 \rightarrow t_2\} \vdash y: t_1 \rightarrow t_2}\;[var]\;\;\frac{}{\{<x,t_1>,<y,t_1 \rightarrow t_2\} \vdash x:t_1}\;[var]}{\{<x,t_1>,<y,t_1 \rightarrow t_2>\} \vdash y\;x: t_2}\;[app]}{\{<x,t_1>\} \vdash (\lambda y:t_1 \rightarrow t_2.\;y\;x): (t_1 \rightarrow t_2) \rightarrow t_2}\; [abs]}{\{\} \vdash (\lambda x:t_1. \lambda y:t_1 \rightarrow t_2.\;y\;x): t_1 \rightarrow (t_1 \rightarrow t_2) \rightarrow t_2} \; [abs]$$

\subsection{Evaluating Type Systems}

- How do we know these type rules work? \\

2 Theorems: {\bf Progress} and {\bf Preservation} \\

\textbf{Theorem (progress):} Let $E$ be a closed, well-typed term in the Simply Typed $\lambda$ Calculus, i.e. for some $A$, $\tau$, $A \vdash E:\tau$. Then either E (E is a value) is in Weak Normal Form or there is an expression $E'$ such that $E \rightarrow_\beta E'$. \\

Proof: Induction on the length of the type derivation for E. \\

Case 1: E is a variable - impossible if E is closed. \\

Case 2: E is an abstraction $\Rightarrow$ E is in Weak Normal Form, done. \\

Case 3: E is an application, $E = M\;N$. Then the type derivation for E looks like $$\frac{\frac{\cdots}{A \vdash M: \tau_1 \rightarrow \tau_2} \; \; \frac{\cdots}{A \vdash N:\tau_1}}{A \vdash E:\tau}$$
 
By induction, M is in Weak Normal Form or reducible \\

By induction, N is in Weak Normal Form or reducible \\

If M or N is reducible, then so is E since $E = M\;N$ \\

If neither is reducible, then both are values \\

In that case, M is a value, $M = \lambda x.M'$, By app rule, M's type derivation must look like
$$\frac{\cdots}{A \vdash (\lambda x.\tau_1. M'): \tau_1 \rightarrow \tau}\;[abs]$$

So $E = M\;N = (\lambda x:\tau_1.M')\;N$ is reducible. (N is $\tau_1$)\\

QED. \\

Simple, but less so when the language is enhanced. \\

{\bf Progress} $\Rightarrow$ can't get stuck, e.g. can't derive $(\lambda x:t_1.A)\;B$ where $B$ is $t_2$ \\

{\bf Theorem (Preservation, aka Subject Reduction Theorem):} Let A be a type environment, P, Q be expressions such that $P \rightarrow_{\beta \eta}^* Q$ (i.e. P reduces to Q in 0 or more $\beta$ and/or $\eta$ reductions). Suppose $A \vdash P: \tau$ for some $\tau$. Then $A \vdash Q:\tau$. \\

Proof: see notes, page 57-58 \\

{\bf Preservation:} Well-typed terms remain well-typed after reduction \\

Progress and Preservation $\Rightarrow$ Safety. \\

Star with E which is well typed, Progress says E is reducible or E is WNF (done). Then if E is not done $E \rightarrow_\beta E'$, from this preservation says $E'$ is well-typed, and then progress says $E'$ is reducible or $E'$ is done. This means $E' \rightarrow_\beta E''$, and then Preservation says $E''$ is well typed, etc. \\

$\therefore$ Well-typed terms either reduce forever, or make a "sensible" value. \\

$\therefore$ Our type rules "make sense" \\

{\bf Strong Normalization Theorem:} The set of well-typed terms in the Simply Typed $\lambda$-Calculus is {\bf strong normalizing} - that is, infinite reductions are impossible. \\

Proof: Appendix B. \\

$\Rightarrow$ Simply typed $\lambda$-Calculus not Turing-complete. (Can't simulate no terminating turing machine)\\

{\bf Intuition:} Consider $(\lambda x.x\;x)(\lambda x.x\;x)$ \\

What type can we give $\lambda x.x\;x$ - How do we type $x\;x$\\

If the 2nd x has some type $\tau_1$, then 1st x must have type $\tau_1 \rightarrow \tau_2$ for some $\tau_2$ \\

No way $\tau_1$ and $\tau_1 \rightarrow \tau_2$ can represent the same type. $\therefore$ no type for x, $\lambda x.x\;x$, $(\lambda x.x\;x)(\lambda x.x\;x)$ \\

Can't type $Y$ either. \\
\end{document}
